# import json
# import joblib
# import os
# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
# from sklearn.svm import SVC
# from sklearn.pipeline import make_pipeline

# # C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n (ph·∫£i kh·ªõp v·ªõi config/settings.py c·ªßa b·∫°n)
# DATA_PATH = "data/nlu_data.json"
# MODEL_PATH = "models/nlu_model.pkl"
# VECTORIZER_PATH = "models/nlu_vectorizer.pkl"

# # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
# os.makedirs("models", exist_ok=True)

# def train_model():
#     print("üîÑ ƒêang t·∫£i d·ªØ li·ªáu hu·∫•n luy·ªán...")
    
#     # 1. ƒê·ªçc d·ªØ li·ªáu
#     with open(DATA_PATH, "r", encoding="utf-8") as f:
#         dataset = json.load(f)

#     texts = [item["text"] for item in dataset]
#     labels = [item["intent"] for item in dataset]

#     print(f"üìä T·ªïng s·ªë m·∫´u c√¢u: {len(texts)}")
#     print("‚öôÔ∏è  ƒêang training AI...")

#     # 2. X·ª≠ l√Ω ng√¥n ng·ªØ (Vectorizer)
#     # TfidfVectorizer gi√∫p m√°y hi·ªÉu t·ª´ quan tr·ªçng (v√≠ d·ª•: 'b·∫≠t' quan tr·ªçng h∆°n 'ƒëi')
#     vectorizer = TfidfVectorizer(ngram_range=(1, 2)) # H·ªçc c·∫£ t·ª´ ƒë∆°n v√† c·ª•m 2 t·ª´
#     X = vectorizer.fit_transform(texts)

#     # 3. Ch·ªçn thu·∫≠t to√°n (SVC l√† t·ªët nh·∫•t cho d·ªØ li·ªáu √≠t)
#     # probability=True ƒë·ªÉ c√≥ th·ªÉ t√≠nh % ƒë·ªô tin c·∫≠y
#     classifier = SVC(kernel='linear', probability=True)
#     classifier.fit(X, labels)

#     # 4. L∆∞u model ra file
#     joblib.dump(classifier, MODEL_PATH)
#     joblib.dump(vectorizer, VECTORIZER_PATH)

#     print("‚úÖ Hu·∫•n luy·ªán xong! ƒê√£ l∆∞u model v√†o th∆∞ m·ª•c 'models/'.")
#     print("   B√¢y gi·ªù b·∫°n c√≥ th·ªÉ ch·∫°y l·∫°i main.py ƒë·ªÉ th·ª≠ nghi·ªám.")

#     # Test th·ª≠ lu√¥n
#     test_sentence = "√°nh s√°ng"
#     vec = vectorizer.transform([test_sentence])
#     pred = classifier.predict(vec)[0]
#     print(f"\nüß™ Test nhanh: '{test_sentence}' -> Intent: {pred}")

# if __name__ == "__main__":
#     train_model()
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import joblib
import os

# ===========================
# 1) Load dataset
# ===========================
df = pd.read_csv("nlu_dataset.csv")

# ===========================
# 2) Train TFIDF vectorizer
# ===========================
vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=1)
X = vectorizer.fit_transform(df["text"])
y = df["intent"]

# ===========================
# 3) Train model
# ===========================
model = LogisticRegression(max_iter=300)
model.fit(X, y)

# ===========================
# 4) T·∫°o th∆∞ m·ª•c output
# ===========================
os.makedirs("output_nlu", exist_ok=True)

# ===========================
# 5) Save model + vectorizer
# ===========================
joblib.dump(model, "output_nlu/intent_model.joblib")
joblib.dump(vectorizer, "output_nlu/tfidf.joblib")

print("üéâ ƒê√£ train l·∫°i NLU v√† t·∫°o 2 file joblib trong th∆∞ m·ª•c output_nlu/")
